[
  {
    "objectID": "pills/tutorials/basic.html",
    "href": "pills/tutorials/basic.html",
    "title": "Basic JUMP data access",
    "section": "",
    "text": "This is a tutorial on how to access We will use polars to fetch the data frame lazily, with the help of s3fs and pyarrow. We prefer lazy loading because the data can be too big to be handled in memory.\n\nimport polars as pl\nfrom pyarrow.dataset import dataset\nfrom s3fs import S3FileSystem\n\nThe shapes of the available datasets are: - crispr: Knock-out genetic perturbations. - orf: Overexpression genetic perturbations. - compounds: Chemical genetic perturbations.\nThe aws paths of the dataframes are shown below:\n\nprefix = (\n    \"s3://cellpainting-gallery/cpg0016-jump-integrated/source_all/workspace/profiles\"\n)\nfilepaths = dict(\n    crispr=f\"{prefix}/chandrasekaran_2024_0000000/crispr/wellpos_cellcount_mad_outlier_nan_featselect_harmony.parquet\",\n    orf=f\"{prefix}/chandrasekaran_2024_0000000/orf/wellpos_cellcount_mad_outlier_nan_featselect_harmony.parquet\",\n    compound=f\"{prefix}/arevalo_2023_e834481/compound/mad_int_featselect_harmony.parquet/\",\n)\n\nWe use a S3FileSystem to avoid the need of credentials.\n\ndef lazy_load(path: str) -&gt; pl.DataFrame:\n    fs = S3FileSystem(anon=True)\n    myds = dataset(path, filesystem=fs)\n    df = pl.scan_pyarrow_dataset(myds)\n    return df\n\nWe will lazy-load the dataframes and print the number of rows and clumns\n\ninfo = {k: [] for k in (\"dataset\", \"#rows\", \"#cols\", \"#Metadata cols\", \"Size (MB)\")}\nfor name, path in filepaths.items():\n    data = lazy_load(path)\n    n_rows = data.select(pl.count()).collect().item()\n    metadata_cols = data.select(pl.col(\"^Metadata.*$\")).columns\n    n_cols = data.width\n    n_meta_cols = len(metadata_cols)\n    estimated_size = int(round(4.03 * n_rows * n_cols / 1e6, 0))  # B -&gt; MB\n    for k, v in zip(info.keys(), (name, n_rows, n_cols, n_meta_cols, estimated_size)):\n        info[k].append(v)\n\npl.DataFrame(info)\n\n\n\nshape: (3, 5)\n\n\n\ndataset\n#rows\n#cols\n#Metadata cols\nSize (MB)\n\n\nstr\ni64\ni64\ni64\ni64\n\n\n\n\n\"crispr\"\n51185\n1119\n8\n231\n\n\n\"orf\"\n72343\n882\n20\n257\n\n\n\"compound\"\n806921\n979\n10\n3184\n\n\n\n\n\n\n\nLet us now focus on the crispr dataset and use a regex to select the metadata columns. Note that the collect() method enforces loading some data into memory.\n\ndata = lazy_load(filepaths[\"crispr\"])\ndata.select(pl.col(\"^Metadata.*$\").shuffle()).head().collect()\n\n\n\nshape: (5, 8)\n\n\n\nMetadata_Source\nMetadata_Plate\nMetadata_Well\nMetadata_JCP2022\nMetadata_Batch\nMetadata_PlateType\nMetadata_Row\nMetadata_Column\n\n\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\n\n\n\n\n\"source_13\"\n\"CP-CC9-R3-23\"\n\"M18\"\n\"JCP2022_803480…\n\"20221024_Run4\"\n\"CRISPR\"\n\"A\"\n\"08\"\n\n\n\"source_13\"\n\"CP-CC9-R5-01\"\n\"P13\"\n\"JCP2022_800574…\n\"20221017_Run3\"\n\"CRISPR\"\n\"L\"\n\"06\"\n\n\n\"source_13\"\n\"CP-CC9-R2-03\"\n\"H02\"\n\"JCP2022_806679…\n\"20221024_Run4\"\n\"CRISPR\"\n\"O\"\n\"17\"\n\n\n\"source_13\"\n\"CP-CC9-R1-25\"\n\"D16\"\n\"JCP2022_801962…\n\"20221109_Run5\"\n\"CRISPR\"\n\"C\"\n\"04\"\n\n\n\"source_13\"\n\"CP-CC9-R2-27\"\n\"P10\"\n\"JCP2022_807318…\n\"20221017_Run3\"\n\"CRISPR\"\n\"N\"\n\"17\"\n\n\n\n\n\n\n\nThe previous block shows that the data frame has 51,850 rows. We can print features The regular expression used here to show the features present alongside the metadata.\n\nheader = data.select(pl.col(\"^X_harmony_000[0-4]$\")).head().collect()\nheader\n\n\n\nshape: (5, 5)\n\n\n\nX_harmony_0000\nX_harmony_0001\nX_harmony_0002\nX_harmony_0003\nX_harmony_0004\n\n\nf32\nf32\nf32\nf32\nf32\n\n\n\n\n8.044376\n-12.273039\n5.13129\n-7.660898\n-4.988223\n\n\n-9.560802\n9.855314\n-3.877071\n3.07043\n-6.270789\n\n\n-5.656524\n8.234575\n3.745233\n-0.52367\n8.401932\n\n\n-14.888161\n12.315203\n-13.380857\n5.450933\n6.240777\n\n\n185.398895\n42.928982\n-2.823193\n30.665529\n10.213488\n\n\n\n\n\n\n\nFinally, we can convert this to pandas if we want to analyse it using that way. Note that if we convert the entire dataframe to pandas it will load it all into memory.\n\nheader.to_pandas()\n\n\n\n\n\n\n\n\n\nX_harmony_0000\nX_harmony_0001\nX_harmony_0002\nX_harmony_0003\nX_harmony_0004\n\n\n\n\n0\n8.044376\n-12.273039\n5.131290\n-7.660898\n-4.988223\n\n\n1\n-9.560802\n9.855314\n-3.877071\n3.070430\n-6.270789\n\n\n2\n-5.656524\n8.234575\n3.745233\n-0.523670\n8.401932\n\n\n3\n-14.888161\n12.315203\n-13.380857\n5.450933\n6.240777\n\n\n4\n185.398895\n42.928982\n-2.823193\n30.665529\n10.213488",
    "crumbs": [
      "Pills",
      "Tutorials",
      "Basic JUMP data access"
    ]
  }
]